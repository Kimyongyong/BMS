# -*- coding: utf-8 -*-
"""BMS_3차년도.ipynb의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WLUBYYL9J5ly0MhvGpH_GuQZQl0Yc5Ub

#⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐
# BMS 3차년도 과제 수행 알고리즘
#⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐
"""

#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
from google.colab import drive
drive.mount('/content/gdrive')

"""## 1. Polynomial regression for R0 evolution over time

### Data Preprocessing
"""

df_new = pd.read_csv('/content/gdrive/My Drive/CP-CuPPc-S-19F.csv', header = [0]).fillna(0)
df = pd.DataFrame()

df["ppm"] = df_new["ppm"]
df["counts"] = df_new["counts"]

df.head()



start_time = T.time()

best_param = {'polynomialfeatures__degree': 3,
              'linearregression__fit_intercept': True,
              'linearregression__normalize': True}

poly_features = PolynomialFeatures(degree = 3, include_bias = False)
poly_reg = LinearRegression()

poly_predict = {}
poly_intercept = {}
poly_coef = {}
rmses3 = {}

for key in data:
  x_poly_train = poly_features.fit_transform(time.reshape(-1,1))
  y_poly_train = data[key].reshape(-1,1)
  poly_reg.fit(x_poly_train, y_poly_train)
  poly_intercept[key] = poly_reg.intercept_
  poly_coef[key] = poly_reg.coef_
  x_poly_test = poly_features.fit_transform(time.reshape(-1,1))
  poly_predict[key] = poly_reg.predict(x_poly_test)
  poly_mse = mean_squared_error(data[key].reshape(-1,1), poly_predict[key])
  poly_rmse = np.sqrt(poly_mse)
  rmses3[key] = poly_rmse

print("--- %s seconds ---" % (T.time() - start_time))

# Plotting those graphs!!

fig, ax = plt.subplots(1,5, figsize = (12,4))
names = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-16th', 'R0-25th']

for i in range(5):
  ax[i].scatter(time, data[names[i]]*1000, label = 'Real', color = 'blue')
  ax[i].plot(time,poly_predict[names[i]]*1000, label = 'Predicted', color = 'red', linewidth = 4)
  ax[i].set_xlabel('Time (seconds)', fontsize = 10)
  ax[i].set_ylabel('R0 (mohms)', fontsize = 10)
  ax[i].legend()

fig.tight_layout()
plt.show()

for key in data:
   print ("Model for {}: / intercept: {} / coefficients: {}".format(key, poly_intercept[key], poly_coef[key]))

fig, ax = plt.subplots(1,5, figsize = (12,4))
names = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-16th', 'R0-25th']
r = np.arange(5)
width = 0.25

for i in range(5):
  ax[i].bar(i, rmses1[names[i]], label = 'n=1', color = 'blue')
  ax[i].bar(i, rmses2[names[i]], label = 'n=2', color = 'red')
  ax[i].bar(i, rmses3[names[i]], label = 'n=3', color = 'g')
  ax[i].set_xlabel(names[i], fontsize = 16)
  ax[i].set_xticks([])
  ax[i].set_ylabel('RMSE', fontsize = 16)
  ax[i].legend()

fig.tight_layout()
plt.show()

"""## 2. Linear regression for each polynomial parameters"""

# Combining the results together
LR_params = {}
LR_params['intercepts'] = []
LR_params['coef_a'] = []
LR_params['coef_b'] = []
LR_params['R0_avg'] = []

for key in poly_intercept:
  LR_params['intercepts'].extend(poly_intercept[key])
  LR_params['coef_a'].append(poly_coef[key][0][0])
  LR_params['coef_b'].append(poly_coef[key][0][1])

for key in data:
  LR_params['R0_avg'].append(np.average(data[key]))

# Linear regression

LR_results = {}
LR_preds = {}
LR_score = {}
LR_intercept = {}
LR_coef = {}

names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

start_time = T.time()

for key in LR_params:
  LR_results[key] = LinearRegression()
  LR_results[key].fit(cycle_numb.reshape(-1,1), LR_params[key])
  LR_preds[key] = LR_results[key].predict(cycle_numb.reshape(-1,1))
  #LR_preds_score[key] = np.sqrt(mean_squared_error(LR_params[key], LR_preds[key]))
  LR_score[key] = LR_results[key].score(cycle_numb.reshape(-1,1), LR_params[key])
  LR_intercept[key] = LR_results[key].intercept_
  LR_coef[key] = LR_results[key].coef_
print("--- %s seconds ---" % (T.time() - start_time))

# Plot the parameters to see the evolution trend!

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].bar(cycle_numb,LR_params[names[i]], color = 'blue')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])
  ax[i].set_xticks(cycle_numb)
  ax[i].set_xticklabels(cycle_numb)

fig.tight_layout()
plt.show()

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].scatter(cycle_numb,LR_params[names[i]], color = 'blue')
  ax[i].plot(cycle_numb, LR_preds[names[i]], color = 'red')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])

fig.tight_layout()
plt.show()

for key in LR_intercept:
  print("The linear regression equation for {} is: {} + {}x"\
        .format(key, LR_intercept[key], LR_coef[key]))

OLS_summary = {}
p_val = {}

for key in LR_results:
  OLS_summary[key] = sm.OLS(LR_params[key],cycle_numb.reshape(-1,1)).fit().summary()
  p_val[key] = sm.OLS(LR_params[key],cycle_numb.reshape(-1,1)).fit().pvalues
  print("P values for {}: {}".format(key, p_val[key]))
  print("======================================== {} ========================================".format(key))
  print(OLS_summary[key])
  print("")

"""## 3. Validation"""

df1 = pd.DataFrame() #R0 - 16th is used as the validation set
df2 = pd.DataFrame() #R0 - 25th is used as the validation set

df1["Time"] = df_new["Time"][:-10]
df1["R0-1st"] = df_new["R0 (1st DSIR)"][:-10]
df1["R0-6th"] = df_new["R0 (6th DSIR)"][:-10]
df1["R0-11th"] = df_new["R0 (11th DSIR)"][:-10]
df1["R0-25th"] = df_new["R0 (25th DSIR)"][:-10]

df2["Time"] = df_new["Time"][:-10]
df2["R0-1st"] = df_new["R0 (1st DSIR)"][:-10]
df2["R0-6th"] = df_new["R0 (6th DSIR)"][:-10]
df2["R0-11th"] = df_new["R0 (11th DSIR)"][:-10]
df2["R0-16th"] = df_new["R0 (16th DSIR)"][:-10]
# Data extraction
cycle_numb1 = np.array([1, 6, 11, 25])
cycle_numb2 = np.array([1, 6, 11, 16])
names1 = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-25th']
names2 = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-16th']


data1 = {}
data2 = {}

for column in df1:
  if column == 'Time':
    time = np.array(df1[column][95003:])
  else:
    data1[column] = np.array(df1[column][95003:])

for column in df2:
  if column == 'Time':
    time = np.array(df2[column][95003:])
  else:
    data2[column] = np.array(df2[column][95003:])

# Data extraction
cycle_numb1 = np.array([1, 6, 11, 25])
cycle_numb2 = np.array([1, 6, 11, 16])
names1 = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-25th']
names2 = ['R0-1st', 'R0-6th', 'R0-11th', 'R0-16th']


data1 = {}
data2 = {}

for column in df1:
  if column == 'Time':
    time = np.array(df1[column][95003:])
  else:
    data1[column] = np.array(df1[column][95003:])

for column in df2:
  if column == 'Time':
    time = np.array(df2[column][95003:])
  else:
    data2[column] = np.array(df2[column][95003:])

best_param = {'polynomialfeatures__degree': 2,
              'linearregression__fit_intercept': True,
              'linearregression__normalize': True}

poly_features = PolynomialFeatures(degree = 2, include_bias = False)

#poly 1
poly_reg1 = LinearRegression()

poly_predict_1 = {}
poly_intercept_1 = {}
poly_coef_1 = {}
rmses_1 = {}

#poly 2
poly_reg2 = LinearRegression()

poly_predict_2 = {}
poly_intercept_2 = {}
poly_coef_2 = {}
rmses_2 = {}

for key in data1:
  x_poly_train = poly_features.fit_transform(time.reshape(-1,1))
  y_poly_train_1 = data1[key].reshape(-1,1)
  poly_reg1.fit(x_poly_train, y_poly_train_1)
  poly_intercept_1[key] = poly_reg1.intercept_
  poly_coef_1[key] = poly_reg1.coef_
  x_poly_test_1 = poly_features.fit_transform(time.reshape(-1,1))
  poly_predict_1[key] = poly_reg1.predict(x_poly_test_1)
  poly_mse_1 = mean_squared_error(data1[key].reshape(-1,1), poly_predict_1[key])
  poly_rmse_1 = np.sqrt(poly_mse_1)
  rmses_1[key] = poly_rmse

print(rmses_1)

for key in data2:
  x_poly_train = poly_features.fit_transform(time.reshape(-1,1))
  y_poly_train_2 = data2[key].reshape(-1,1)
  poly_reg2.fit(x_poly_train, y_poly_train_2)
  poly_intercept_2[key] = poly_reg2.intercept_
  poly_coef_2[key] = poly_reg2.coef_
  x_poly_test_2 = poly_features.fit_transform(time.reshape(-1,1))
  poly_predict_2[key] = poly_reg2.predict(x_poly_test_2)
  poly_mse_2 = mean_squared_error(data2[key].reshape(-1,1), poly_predict_2[key])
  poly_rmse_2 = np.sqrt(poly_mse_2)
  rmses_2[key] = poly_rmse_2

print(rmses_2)

# Plotting those graphs!!

fig, ax = plt.subplots(1,4, figsize = (12,4))

for i in range(4):
  ax[i].scatter(time, data1[names1[i]]*1000, label = 'Real', color = 'blue')
  ax[i].plot(time,poly_predict_1[names1[i]]*1000, label = 'Predicted', color = 'red', linewidth = 4)
  ax[i].set_xlabel('Time (seconds)', fontsize = 10)
  ax[i].set_ylabel('R0 (mohms)', fontsize = 10)
  ax[i].legend()

fig.tight_layout()
plt.show()

for key in data1:
   print ("Model for {}: / intercept: {} / coefficients: {}".format(key, poly_intercept_1[key], poly_coef_1[key]))

# Plotting those graphs!!

fig, ax = plt.subplots(1,4, figsize = (12,4))

for i in range(4):
  ax[i].scatter(time, data2[names2[i]]*1000, label = 'Real', color = 'blue')
  ax[i].plot(time,poly_predict_2[names2[i]]*1000, label = 'Predicted', color = 'red', linewidth = 4)
  ax[i].set_xlabel('Time (seconds)', fontsize = 10)
  ax[i].set_ylabel('R0 (mohms)', fontsize = 10)
  ax[i].legend()
  ax[i].set_title(names2[i])

fig.tight_layout()
plt.show()

for key in data2:
   print ("Model for {}: / intercept: {} / coefficients: {}".format(key, poly_intercept_2[key], poly_coef_2[key]))

# Combining the results together
LR_params1 = {}
LR_params1['intercepts'] = []
LR_params1['coef_a'] = []
LR_params1['coef_b'] = []
LR_params1['R0_avg'] = []

for key in poly_intercept_1:
  LR_params1['intercepts'].extend(poly_intercept_1[key])
  LR_params1['coef_a'].append(poly_coef_1[key][0][0])
  LR_params1['coef_b'].append(poly_coef_1[key][0][1])

for key in data1:
  LR_params1['R0_avg'].append(np.average(data1[key]))

# Linear regression

LR_results1 = {}
LR_preds1 = {}
LR_score1 = {}
LR_intercept1 = {}
LR_coef1 = {}

names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for key in LR_params1:
  LR_results1[key] = LinearRegression()
  LR_results1[key].fit(cycle_numb1.reshape(-1,1), LR_params1[key])
  LR_preds1[key] = LR_results1[key].predict(cycle_numb1.reshape(-1,1))
  #LR_preds_score[key] = np.sqrt(mean_squared_error(LR_params[key], LR_preds[key]))
  LR_score1[key] = LR_results1[key].score(cycle_numb1.reshape(-1,1), LR_params1[key])
  LR_intercept1[key] = LR_results1[key].intercept_
  LR_coef1[key] = LR_results1[key].coef_

# Combining the results together
LR_params2 = {}
LR_params2['intercepts'] = []
LR_params2['coef_a'] = []
LR_params2['coef_b'] = []
LR_params2['R0_avg'] = []

for key in poly_intercept_2:
  LR_params2['intercepts'].extend(poly_intercept_2[key])
  LR_params2['coef_a'].append(poly_coef_2[key][0][0])
  LR_params2['coef_b'].append(poly_coef_2[key][0][1])

for key in data2:
  LR_params2['R0_avg'].append(np.average(data2[key]))

# Linear regression

LR_results2 = {}
LR_preds2 = {}
LR_score2 = {}
LR_intercept2 = {}
LR_coef2 = {}

names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for key in LR_params2:
  LR_results2[key] = LinearRegression()
  LR_results2[key].fit(cycle_numb2.reshape(-1,1), LR_params2[key])
  LR_preds2[key] = LR_results2[key].predict(cycle_numb2.reshape(-1,1))
  #LR_preds_score[key] = np.sqrt(mean_squared_error(LR_params[key], LR_preds[key]))
  LR_score2[key] = LR_results1[key].score(cycle_numb2.reshape(-1,1), LR_params2[key])
  LR_intercept2[key] = LR_results2[key].intercept_
  LR_coef2[key] = LR_results2[key].coef_

# Plot the parameters to see the evolution trend!

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].bar(cycle_numb1,LR_params1[names[i]], color = 'blue')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])
  ax[i].set_xticks(cycle_numb1)
  ax[i].set_xticklabels(cycle_numb1)

fig.tight_layout()
plt.show()

# Plot the parameters to see the evolution trend!

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].bar(cycle_numb2,LR_params2[names[i]], color = 'blue')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])
  ax[i].set_xticks(cycle_numb2)
  ax[i].set_xticklabels(cycle_numb2)

fig.tight_layout()
plt.show()

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].scatter(cycle_numb1,LR_params1[names[i]], color = 'blue')
  ax[i].plot(cycle_numb1, LR_preds1[names[i]], color = 'red')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])

fig.tight_layout()
plt.show()

for key in LR_intercept1:
  print("The linear regression equation for {} is: {} + {}x"\
        .format(key, LR_intercept1[key], LR_coef1[key]))

fig, ax = plt.subplots(1,4, figsize = (12,4))
names = ['intercepts', 'coef_a', 'coef_b', 'R0_avg']

for i in range(4):
  ax[i].scatter(cycle_numb2,LR_params2[names[i]], color = 'blue')
  ax[i].plot(cycle_numb2, LR_preds2[names[i]], color = 'red')
  ax[i].set_xlabel('Cycle number', fontsize = 10)
  ax[i].set_title(names[i])

fig.tight_layout()
plt.show()

for key in LR_intercept2:
  print("The linear regression equation for {} is: {} + {}x"\
        .format(key, LR_intercept2[key], LR_coef2[key]))

# 26km model expected linear regression equations
params_25km = {}
params_16km = {}
dd = 25
dd2 = 16

params_25km['intercept'] = -0.0009622872997038174 + 0.00060983*dd
params_25km['coef_a'] = 8.717396040822358e-08 + 2.09866725e-08*dd
params_25km['coef_b'] = -1.0352508361441786e-11 + 5.65217917e-13*dd
params_25km['R0_avg'] = -0.0008141451965687748 + 0.00070858*dd

params_16km['intercept'] = -0.0008747460025933518 + 0.00058806*dd2
params_16km['coef_a'] = -3.7336486461425275e-08 + 4.72100691e-08*dd2
params_16km['coef_b'] = 1.8304565886035808e-13 + -1.63326424e-12*dd2
params_16km['R0_avg'] =  -0.001025910937398981 + 0.00075028*dd2

model_25 = params_25km['intercept'] + params_25km['coef_a']*time + params_25km['coef_b']*np.power(time,2)
model_16 = params_16km['intercept'] + params_16km['coef_a']*time + params_16km['coef_b']*np.power(time,2)

model_25_accuracy = abs(100*(model_25 - data['R0-25th'])/model_25)

# model_25_rmse = 적어야혀~~

model_16_accuracy = abs(100*(model_16 - data['R0-16th'])/model_16)

# model_16_rmse = 적어야혀~~

fig, ax = plt.subplots(1,3, figsize = (12,4))
x = time

ax[0].scatter(time, data['R0-25th']*1000, color = 'blue')
ax[0].plot(time, model_25*1000, color = 'red', linewidth=4)
ax[0].set_xlabel('Time (seconds)', fontsize = 10)
ax[0].set_ylabel('R0 (mohms)')
ax[0].set_title('R0 evolution')

ax[1].plot(time, model_25_accuracy)
ax[1].set_xlabel('Time (seconds)', fontsize = 10)
ax[1].set_ylabel('Error (%)')
ax[1].set_title('Model accuracy')

ax[2].plot(time, model_16_accuracy)
ax[2].set_xlabel('Time (seconds)', fontsize = 10)
ax[2].set_ylabel('RMSE')
ax[2].set_title('Model accuracy')

fig, ax = plt.subplots(1,3, figsize = (12,4))
x = time

ax[0].scatter(time, data['R0-16th']*1000, color = 'blue')
ax[0].plot(time, model_16*1000, color = 'red', linewidth=4)
ax[0].set_xlabel('Time (seconds)', fontsize = 10)
ax[0].set_ylabel('R0 (mohms)')
ax[0].set_title('R0 evolution')

ax[1].plot(time, model_16_accuracy)
ax[1].set_xlabel('Time (seconds)', fontsize = 10)
ax[1].set_ylabel('Error (%)')
ax[1].set_title('Model accuracy')

ax[2].plot(time, model_16_accuracy)
ax[2].set_xlabel('Time (seconds)', fontsize = 10)
ax[2].set_ylabel('RMSE')
ax[2].set_title('Model accuracy')

np.average(model_16_accuracy)
# np.average(model_25_accuracy)

np.max(model_16_accuracy)
# np.min(model_16_accuracy)

0.0000084

# === 잔존가치 추정 함수 ===
def estimate_cycle(R0_measured, lr_intercept, lr_slope):
    """
    R0_measured : 측정된 내부저항 값 (float)
    lr_intercept : cycle-R0 회귀식 절편 (alpha)
    lr_slope : cycle-R0 회귀식 기울기 (beta)
    """
    return (R0_measured - lr_intercept) / lr_slope


# === 예시: 기존 코드에서 얻은 회귀식 값 불러오기 ===
alpha = LR_intercept['R0_avg']     #
beta  = LR_coef['R0_avg']          #

# === 실제 내부저항 입력 창 ===
R0_input = 0.0112   # 예: 현재 측정된 R0 (Ohm)

# === 잔존가치 추정 ===
estimated_cycle = estimate_cycle(R0_input, alpha, beta)

print("추정된 사이클 수 ≈", float(estimated_cycle))